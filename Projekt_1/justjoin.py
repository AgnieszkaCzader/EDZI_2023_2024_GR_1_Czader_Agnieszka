# -*- coding: utf-8 -*-
"""justjoin.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DgYvbipckrF9zA153_J0YWkFGf8tM9ny
"""

import urllib.parse
import requests
from bs4 import BeautifulSoup
import time
import re
import json

# Analiza wynagrodzenia

def parse_salary(salary_text):
    # Wyrażenie regularne do dopasowania wartości liczbowych
    regex_salary = r'\d{1,3}(?:\s\d{3})*(?:[.,]\d+)?'

    # Dopasowanie wartości liczbowych
    salaries = re.findall(regex_salary, salary_text)

    # Usuwanie znaków specjalnych, spacji
    salaries = [int(s.replace('\xa0', '').replace(' ', '')) for s in salaries if s.strip()]

    # Sprawdzenie waluty
    if 'PLN' in salary_text:
        currency = 'zł'
    elif 'USD' in salary_text:
        currency = 'USD'
    elif 'EUR' in salary_text:
        currency = 'EUR'
    else:
        currency = 'inna'

    # Jeśli mamy więcej niż dwie wartości to odrzucamy pozostałe
    if len(salaries) > 2:
        salaries = salaries[:2]

    # Ustawienie, że pierwsza wartość jest minimalna, a druga maksymalna
    if len(salaries) == 2:
        min_salary, max_salary = salaries
    elif len(salaries) == 1:
        min_salary = salaries[0]
        max_salary = None
    else:
        min_salary = max_salary = None

    # Sprawdzenie, czy wynagrodzenie jest netto
    if 'Net' in salary_text:
        # Dodanie podatku jeśli wynagrodzenie jest w netto
        min_salary *= 1.23
        if max_salary is not None:
            max_salary *= 1.23

    return min_salary, max_salary, currency

# Główna funkcja - wyszukanie danych i stworzenie listy

def find_job_details(search_url, job_title, max_pages=1):
    all_job_details = []

    for page in range(1, max_pages + 1):
        response = requests.get(f"{search_url}{urllib.parse.quote(job_title)}&pn={page}")
        soup = BeautifulSoup(response.text, 'html.parser')

        # Linki do ofert
        offer_links = soup.find_all('a', class_='offer_list_offer_link css-4lqp8g', href=True)
        # Nazwa firmy
        company_names = soup.select('svg[data-testid="ApartmentRoundedIcon"] + span')
        # Tytuły ofert
        offer_titles = soup.find_all('h2', class_='css-1gehlh0')

        job_details = []

        for i, (link_element, company_element, title_element) in enumerate(zip(offer_links, company_names, offer_titles)):

            # sposób wyświetlania danych
            link = urllib.parse.urljoin(search_url, link_element['href'])  # Utworzenie pełnego adresu URL
            company_name = company_element.text.strip()
            offer_title = title_element.text.strip()

            # dodanie źródła
            source = "www.justjoin.it"

            # Wchodzenie na strony z ofertami pracy
            offer_response = requests.get(link)
            offer_soup = BeautifulSoup(offer_response.text, 'html.parser')

            # Wyszukiwanie stanowiska
            experience_level = None
            divs = offer_soup.find_all('div', class_='css-6q28fo')
            for div in divs:
                type_of_work_div = div.find('div', class_='css-qyml61')
                if type_of_work_div and type_of_work_div.text.strip() == 'Experience':
                    experience_level_div = type_of_work_div.find_next_sibling('div', class_='css-15wyzmd')
                    if experience_level_div:
                        experience_level = experience_level_div.text.strip()
                        break

            # Wyszukiwanie programów
            technology_tags = offer_soup.select('.MuiTypography-root.MuiTypography-subtitle2.css-x1xnx3')
            technologies = [tag.text.strip() for tag in technology_tags]

            # Wynagrodzenie
            salary_tag = offer_soup.find("meta", {"name": "description", "property": "og:description"})
            salary = None
            if salary_tag:
                salary_content = salary_tag.get("content", "")
                # Wyodręnienie wynagrodzenia
                salary = salary_content.split("|")[0].strip()

                # Parsowanie wynagrodzenia
                min_salary, max_salary, currency = parse_salary(salary)

            # Zebranie danych
            job_details.append({
                "link_oferty": link,
                "tytuł_oferty": offer_title,
                "firma": company_name,
                "stanowisko": experience_level,
                "wynagrodzenie": salary,
                "wynagrodzenie_minimalne": min_salary,
                "wynagrodzenie_maksymalne": max_salary,
                "waluta": currency,
                "źródło": source,
                "Array": technologies,
                "kategoria": "Data"
            })


        all_job_details.extend(job_details)

        # Dodanie opóźnienia (1 sekudna)
        time.sleep(1)

    return all_job_details

# Ustawienie linku do strony

def search_job_details(job_title, max_pages=4):
    search_url = 'https://justjoin.it/krakow/data/experience-level_junior.mid.senior/with-salary_yes?index=0'
    job_details = find_job_details(search_url, job_title, max_pages)
    return job_details

result = search_job_details("", max_pages=4)

# Zapisanie pliku z danymi

def save_to_json(data, filename='job_details_justjoin.json'):
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=4)
    print(f"Dane zostały zapisane do pliku: {filename}")

# Pobranie pliku z danymi

def download_json(filename='job_details_justjoin.json'):
    from google.colab import files
    files.download(filename)
    print("Plik JSON został pobrany na Twój komputer.")

# Utworzenie raportu - zliczenie programów

def generate_technology_report(job_details):
    technology_count = {}

    # Sprawdzenie każdej oferty pracy
    for job_detail in job_details:
        # Pobranie listy programów dla każdej oferty
        technologies = job_detail.get("Array", [])

        # Zsumowanie programów
        for technology in technologies:
            technology_count[technology] = technology_count.get(technology, 0) + 1

    return technology_count

# Utworzenie raportu - zliczenie stanowisk i płac

# Informacje do raportu
def generate_position_report(job_details):
    position_count = {
        "Junior Data Engineer": {"count": 0, "min_salary": None, "max_salary": None, "average_salary": None},
        "[Mid/Regular] Data Engineer": {"count": 0, "min_salary": None, "max_salary": None, "average_salary": None},
        "Senior Data Engineer": {"count": 0, "min_salary": None, "max_salary": None, "average_salary": None},
        "Junior Data Analyst": {"count": 0, "min_salary": None, "max_salary": None, "average_salary": None},
        "[Mid/Regular] Data Analyst": {"count": 0, "min_salary": None, "max_salary": None, "average_salary": None},
        "Senior Data Analyst": {"count": 0, "min_salary": None, "max_salary": None, "average_salary": None},
        "Junior Data Scientist": {"count": 0, "min_salary": None, "max_salary": None, "average_salary": None},
        "[Mid/Regular] Data Scientist": {"count": 0, "min_salary": None, "max_salary": None, "average_salary": None},
        "Senior Data Scientist": {"count": 0, "min_salary": None, "max_salary": None, "average_salary": None},
        "Junior Data Architect": {"count": 0, "min_salary": None, "max_salary": None, "average_salary": None},
        "[Mid/Regular] Data Architect": {"count": 0, "min_salary": None, "max_salary": None, "average_salary": None},
        "Senior Data Architect": {"count": 0, "min_salary": None, "max_salary": None, "average_salary": None}
    }

    # Sprawdzenie każdej oferty pracy
    for job_detail in job_details:
        # Pobranie tytułów ofert pracy
        title = job_detail.get("tytuł_oferty", "")

        # Pobranie wynagrodzeń minimalnych i maksymalnych
        min_salary = job_detail.get("wynagrodzenie_minimalne")
        max_salary = job_detail.get("wynagrodzenie_maksymalne")

        # Pobranie informacji o stanowisku
        experience_level = job_detail.get("stanowisko", "")

        # Zliczenie wystąpienia każdego stanowiska i sprawdzenie wynagrodzenia minimalnego i maksymalnego
        for position, position_info in position_count.items():
            if position in title:
                position_info["count"] += 1
                if position_info["min_salary"] is None or (min_salary is not None and min_salary < position_info["min_salary"]):
                    position_info["min_salary"] = min_salary
                if position_info["max_salary"] is None or (max_salary is not None and max_salary > position_info["max_salary"]):
                    position_info["max_salary"] = max_salary

    # Obliczenie średniego wynagrodzenie dla każdego stanowiska
    for position, position_info in position_count.items():
        if position_info["count"] > 0:
            if position_info["max_salary"] is not None:
                position_info["average_salary"] = (position_info["min_salary"] + position_info["max_salary"]) / 2
            else:
                position_info["average_salary"] = position_info["min_salary"]

    return position_count

# Zapisanie raportu

def save_to_json(data, filename='technology_report_justjoin.json'):
    with open(filename, 'w', encoding='utf-8') as file:
        json.dump(data, file, ensure_ascii=False, indent=4)

# Pobranie raportu

def download_json(filename='technology_report_justjoin.json'):
    from google.colab import files
    files.download(filename)
    print("Plik JSON został pobrany na Twój komputer.")

# Wywołania funkcji

job_details = search_job_details("", max_pages=4)
technology_report = generate_technology_report(result)

save_to_json(technology_report, filename='technology_report_justjoin.json')

# Generowanie raportu dotyczącego stanowisk
position_report = generate_position_report(result)

# Dodanie raportu dotyczącego stanowisk do istniejącego raportu
for position, count in position_report.items():
    technology_report[position] = count

# Zapisanie zaktualizowanego raportu
save_to_json(technology_report, filename='technology_report_justjoin.json')

# Zapisanie i pobranie plików
save_to_json(job_details, filename='job_details_justjoin.json')
download_json(filename='technology_report_justjoin.json')
download_json(filename='job_details_justjoin.json')