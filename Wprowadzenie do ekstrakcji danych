import requests
from bs4 import BeautifulSoup

def get_text(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    # mw-parser-output to klasa HTML uzywana na platformie MediaWiki - jest glownym kontenerem dla tresci
    content = soup.find('div', class_='mw-parser-output').text
    return content

def process_text(text):
    text = text.lower()
text_without_special = ''.join(char for char in text if char.isalnum() or char.isspace())
    return text_without_special

def get_ranked_words(text):
    ranked_words = None
    words = re.findall(r'\b\w+\b', text)
    word_counts = Counter(words)
    ranked_words = word_counts.most_common(100)
    return ranked_words

def write_results(results, filename):
    with open(filename, 'w') as file:
    file.write("Ranking;Słowo;Ilość wystąpień\n")
        for i, (word, count) in enumerate(results, start=1):
            file.write(f"{i};{word};{count}\n")
        pass

def main():
    url = 'https://en.wikipedia.org/wiki/Web_scraping'
    text = get_text(url)
    cleaned_text = process_text(text)
    final_words = get_ranked_words(cleaned_text)
    write_results(final_words, 'output.txt')

if __name__ == "__main__":
    main()
